---
layout: post
title: "Year in Review: 2024"
description: "A review of major lab highlights from 2024"
author: "Mark Fuge"
author_handle: fuge
category: blog
published: true
redirect_from:
theme: lab
tags: [year-in-review]
---


Year in Review: 2024
===============================================================

> Summary: A copy of my end-of-year message to my lab and lab alumni, where I review the key events from 2024.

Wow, what a year! While I anticipated this year would be much busier than [past years](http://ideal.umd.edu/blog/year-in-review-2023), the shear number and magnitude of changes was on a whole other level due in large part to moving my family and the lab to Zürich. I certainly could not have managed all of this without your help across multiple fronts, and so I am extremely thankful to have such a dedicated team. Not only did many of you help out getting things set up for IDEAL@Zürich, but many also chipped in to keep things running smoothly for IDEAL@UMD during this transition. Thank you again for everything you have done for me and the lab this year and I'll highlight a few (though certainly not all) of what you have all been up to this year.


# The People

We had some good lab retreats focusing on lab collaboration and research topics (along with successfully navigating an Escape Room -- see picture below) that I think has led to many more collaborative projects and ideas that I think will bare fruit in one to two years time. I also feel like I have seen a lot of strong growth in each member of the lab this year, as we had a bunch of people join the Ph.D. program around the same time a few years ago, and now folks are finishing their classes and really blossoming into their own in terms of research directions, which is always really great to see.

![IDEAL Lab Retreat May 2024](/assets/images/news/retreat_may_2024_group_photo.jpg "IDEAL Lab Retreat May 2024"){: width="800"}
![IDEAL Lab Escape Room 2024](/assets/images/news/retreat_may_2024_escape_room.jpg "IDEAL Lab solves an Escape Room"){: width="800"}

More so than in the past, this year had a large flux in terms of people. In terms of new additions, this was a banner year for the lab due to a confluence of factors that included the launch of a big UMD project (the ETL Project) plus the opening of the lab in Zürich, both of which required significant investments across both locations. Specifically, at UMD we were lucky to be joined by Dr. Frank VanGessel who joins the lab as a Research Assistant Professor and has been a driving force in keeping both the ETL project and the UMD lab running smoothly. Along with Frank, Dr. Gabe Apaza from Dani Selva's lab at Texas A&M joined the UMD lab as a Post-Doc on the ETL project and has been doing some really cool work on Transfer Learning and Reinforcement Learning that we look forward to sharing with the world in the coming year or so. On the Zürich side, Cashen and Matt transferred over to the ETHZ Ph.D. program after completing their Masters at UMD, and Nathan and Arthur will be coming over as Academic Guests to ETHZ while they finish their UMD Ph.D.s. To help set up the ETHZ lab during our first few years and pursue some new directions, we were joined by three post-docs, Dr. Florian Felten, Dr. Milli Schlafly, and Dr. Soheyl Massoudi, and they have done a great job with helping me juggle the many balls that are needed to transition the lab to a new location.

We also had several notable departures this past year, and while it is always hard for me to say goodbye to students I have worked with for so long, it is also great to see how far they have come and to see them move onto bigger and better things. Specifically, in early January, [Dr. Xuan Liang](https://dr.ntu.edu.sg/cris/rp/rp02364) started his Assistant Professor position at Nanyang Technological University in Singapore where he looks like he is off to a great start building his team there and pursuing several interesting new directions in the design, ML, and manufacturing space. Later that January, [Dr. Nicholas Chiu](https://faculty.eng.umd.edu/clark/faculty/1925/Kevin-Nicholas-Chiu) successfully defended his dissertation ("Automated Simulation and the Discovery of Mechanical Devices") and decided to pursue his dream of being a Teaching-Track faculty member. It is great that we get to keep his abilities close at hand, as he started as a Full-time Lecturer in UMD's College of Engineering [Keystone program](https://eng.umd.edu/keystone) supporting both the design courses and some of the new initiatives in the Artificial Intelligence for All (AI4All) initiative. [Dr. Sangeeth Balakrishnan](https://www.linkedin.com/in/sangeeth-balakrishnan-phd-a8689a44/), who I co-advised with Dr. Peter Chung, also graduated this year in May after submitting his dissertation ("Machine Learning in Scarce Data Regime for Design and Discovery of Materials"). He is now continuing at UMD as a Post-Doctoral Research Associate in Peter's lab. [Dr. Qiuyi Chen](https://www.linkedin.com/in/qiuyi-chen-joey/) submitted his dissertation in November ("Analyzing Inverse Design Problems from a Topological Perspective"), and will head to GE Global Research in Niskayuna as a Researcher (specifically GE Vernova Advanced Research, now that GE has split into several sub-companies). Lastly, our High School intern Xavier Francois, completed his senior research practicum in May, and has now joined UMD as a Freshman where he is working in an Electrical Engineering lab.

![Nicholas Graduation](/assets/images/news/nicolas_graduation.jpg "Nicholas Graduation"){: width="800" }
# The Science

This year we have continued putting out papers that were in the works from our past ARPA-E, NIH, and NSF CAREER projects, and it is nice to be able to finally share some of those results with people. As always, you can get a list of recent papers by checking out [our website's papers page](https://ideal.ethz.ch/publications.html) or the automatically updated [Google Scholar](https://scholar.google.com/citations?user=rgvbw14AAAAJ&hl=en), but I'll highlight a few key threads here:

* We published two papers in AIAA SciTech this year. The first was by Dr. Jun Wang who showed how to improve the performance of Generative Models for Inverse Design (ID) by actively selecting the training dataset ([Training Efficiency Gains in Data-Driven 2D Airfoil Inverse Design using Active Learning](https://doi.org/10.2514/6.2024-1229))-- this reduces the amount of expensive training data you need to generate equivalently performance ID models by a significant margin. The second was by Cashen Diniz and focused on Diffusion models for Aerodynamic optimization ([Optimizing Diffusion to Diffuse Optimal Designs](https://doi.org/10.2514/6.2024-2013)) where we investigated how to incorporate information from prior optimization trajectories to improve performance of the diffusion model.
* At IDETC this year we had several papers: First, Matt's work as part of our NSF CAPS project on was published in DTM this year and focused on aligning LLM and human-provided similarity comparisons ([A Picture or a Thousand Words: Design Description Crafting to Replicate Human Similarity Judgments in Large Language Models](https://doi.org/10.1115/DETC2024-143634)). Milad's paper on [Inverse Design With Conditional Cascaded Diffusion Models](https://doi.org/10.1115/DETC2024-143607) explored how to minimize the high cost of data generation for Inverse Design by training super-resolution models with mixtures of low-quality/cost and high-quality/cost data. Lastly, Arthur presented some of his work on the effect of discrete quantization in latent code books and its effect on preserving topological changes with his [To Quantize or Not to Quantize: Effects on Generative Models for 2D Heat Sink Design](https://doi.org/10.1115/DETC2024-142052) paper.
* One new experience for me this year was attending ICLR 2024 to present Qiuyi's [Compressing Latent Space via Least Volume](https://arxiv.org/abs/2404.17773) paper since he was not able to travel to Austria for the conference. (First time I've had to give a presentation of a student's paper in over a decade!) "Least Volume" is a really powerful technique that we have been exploring in other context's in the lab, including for [Bayesian Inverse Problems](https://arxiv.org/abs/2405.14008). We have some exciting improvements on Least Volume that we hope to share with the world next year. 
* Milad's work on [Automatic Laplacian-based shape optimization for patient-specific vascular grafts](https://doi.org/10.1016/j.compbiomed.2024.109308) our NIH Aorta project finally came out in CIBM earlier this Fall and builds upon some of the experimental work the rest of the team published in [JCTVS Open](https://doi.org/10.1016/j.xjon.2024.02.012)

On the education side, we hosted the third [*Frontiers in Design Representation* (FinDeR) Summer School](https://ideal.umd.edu/FinDeR/2024/schedule/). This built on the structure of last two years, which covered "Designs as Distributions: Optimal Transport, Information Geometry, and Generative Models" and "Designs as Programs: Induction, Analysis, and Generation" respectively but this year we moved to the topic of "Designs as Topologies – Differential Topology, Algebraic Topology, and Topological Data Analysis." As with the past Summer Schools, I had been looking forward to this all year and once again it did not disappoint. It is always so much work to put on and organize, but meeting so many bright students and watching them create new friendships with others in the field is the kind of personally fulfilling activity that it is hard to get anywhere else. See below for some photos! (1) a group photo at FinDeR we took on the last day right before the final presentations and a reunion photo some of the FinDeR students took at IDETC '24, which included students from the first two years as well. 

One of the hard parts of moving to Zürich was that the funds for the FinDeR program were tied to my NSF CAREER grant, which I had to relinquish when I moved abroad. This means I am not quite sure what the future of the FinDeR series holds, but I am exploring ways to pick it up here using other funding vehicles. We'll see how it goes, but perhaps the next one will be in the Alps in a few years time!
![FinDeR 2024 Group Photo](/assets/images/news/finder_2024_group_photo.jpg "FinDeR 2024 Group Photo"){: width="800" }

![FinDeR 2023 IDETC Reunion](/assets/images/news/finder_reunion_idetc_2024.jpg "FinDeR 2024 IDETC Reunion"){: width="800" }
# The Field

Broadly there continues to be interest at the intersection of Machine Learning and Design and it appears to be accelerating in concert with general interesting Machine Learning area. This year in particular it seems that progress has developed rapidly on multiple fronts. I think this is due to a couple of different factors that are all kind of coming together at the same time in a fortuitous way.

First, there is immense interest in the general scientific machine learning area with multiple labs exploring things like foundation models for solving PDEs. There are workshops and topics like these at all of the main ML conferences and in talking with experts in this area the general impression I get is that we are very close to having fairly fast neural surrogate models for almost any physical field like flow, stress, or thermal fields, etc. I would not at all be surprised if in the next year or two we will have decent robust open source neural foundation models of an acceptable accuracy to be useful for design purposes, at least for one or two coupled physics.

Second, I would say that the rise of interest in transformers and large language models has really spilled over into a wide variety of libraries and companies focused on the general area of "Text-to-CAD." By this I mean describing an object with either an image/sketch or a sentence and having it produce a valid Mesh, BRep, or CSG representation that is compatible with most solid modeling programs. We had a speaker on this during our 2023 FinDeR summer school, so I thought it would still be a few years. But now I would not be surprised at all if, for many purposes, existing generative models will be decent at producing perfectly reasonable CAD representations of common objects by the end of 2025 and perhaps even be available in commercial modeling packages.

Third, there is now **way** more industrial interest, whether in traditional companies or startups, than there was even a few years ago. Multiple startups are exploring neural-based PDE solvers, for example, and others are exploring inverse design or tradespace visualization or analysis. Case in point, former IDEAL Post-Doc David Anderson's start-up Engora Inc. operates in this space. I was surprised (pleasantly) to see that Y Combinator's ["Request for Startups" in Winter 2025](https://www.ycombinator.com/rfs) specifically asked for "AI-aidez Engineering Tools" (they even made a [short YouTube pitch here](https://youtube.com/shorts/1asr6PkU8HQ?feature=shared)) To think that when I started at UMD at decade ago we would be at a stage now where there would be the requested start-up spaces is quite phenomenal and really speaks I think to the growth potential of the field in general.

All of this is happening in the context of an already vibrant academic scene too, with special sessions, journal special issues, workshops and many other opportunities for getting folks involved. This really does feel like an exciting time to be alive and working in this space with so much technological development and interest around us. 

To be honest, my main concern in all of this is for our research to remain relevant and boundary advancing in the context of all this other investment. I used to think that we as a lab should be working on topics like neural surrogate models and generative models of geometry — and I think our past work in that vein led in part to some of the things we are seeing today (or at least I suspect our datasets probably are) — but going forward I think the "bar has been raised" so to speak and that we can now be way more aggressive in our research vision for the future than we could have been even threw years ago. I think we are at an interesting inflection point in the field right now, and I'm excited to see how some of the things we have planned will pivot towards this expanded set of possibilities going forward. More to share on that in the coming years.

# Alumni News

Occasionally, I'll get some updates from past lab alumni that I like to share with the lab family each year.

[Kailyn Cage](https://www.linkedin.com/in/kailyn-c-4b32188/) has moved back to the DC area to begin a role as a Technical Program Manager at Google -- it was great to catch up again at the lab reunion after so much time. [Dan Elton](https://www.moreisdifferent.com/) has also moved back to the DC area to take a role at the NIH as a Senior Scientist in the National Human Genome Research Institute. As mentioned above, Xuan started his role as an Assistant Prof. at NTU in January. Wei's lab is now underway and producing some cool work with some great students I got to meet during both the reunion and the FinDeR summer school. He is also coordinating a Special Issue for JCISE in 2025 in the ML+Design space, so definitely keep a look out for that. In a similar vein, Faez is coordinating a different SI for CAD in 2025, so there should be many publishing opportunities next year for folks in our area. He is also co-organizing a workshop on [Generative AI for Design](https://sites.mit.edu/genaifordesign/) in May where I will be speaking, so if folks are going to that or in the Boston area around that time I'd be happy to meet up.

Of course the big alumni news of this year was the lab's 10 year reunion we held at IDETC 2024 in DC. Thank you so much to everyone who came out for this, as it was an absolute blast. In particular, it was great to see some alumni being their own lab members (thanks Jun, Wei, and Faez!) so that we could celebrate together and build a supportive network for each other. The culmination of the move, plus the reunion, plus all of the great things our current members and alumni have been up to has made this year into a remarkably emotional one for me that I don't think will have an easy parallel for some time.
![Lab 10 Year Reunion](/assets/images/news/lab_10_year_reunion_idetc_2024.jpg "Lab 10 Year Reunion"){: width="800" }

As always, I am sure that I missed several updates from folks in the lab, and I apologize if so -- I always appreciate hearing about how things are going, so do let me know about any updates.

Thanks again to everyone for your hard work this year and I'm definitely looking forward to 2025 and all the exciting things it has in store for us!